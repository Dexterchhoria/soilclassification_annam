{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102672,"databundleVersionId":12375409,"sourceType":"competition"},{"sourceId":11930983,"sourceType":"datasetVersion","datasetId":7500973}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:34.104614Z","iopub.execute_input":"2025-05-24T09:55:34.104981Z","iopub.status.idle":"2025-05-24T09:55:35.166675Z","shell.execute_reply.started":"2025-05-24T09:55:34.104943Z","shell.execute_reply":"2025-05-24T09:55:35.165548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===============================\n# Soil Image Classification Challenge\n# Author: Siddharth Chhoria\n# Date: [24/05/25]\n# ===============================\n\n# --- 1. Library Imports ---\n# Import all necessary libraries for data manipulation, model building, and evaluation.\n\nimport numpy as np                    # For numerical operations\nimport pandas as pd                   # For dataframes and data analysis\nimport torch                          # For PyTorch tensor operations and model building\nimport torch.nn as nn                 # For neural network layers and loss functions\nfrom torch.utils.data import Dataset, DataLoader  # For custom dataset and batching\nimport torchvision.transforms as transforms       # For image augmentations and preprocessing\nimport torchvision.models as models              # For pretrained CNN architectures\nfrom PIL import Image                 # For image loading and processing\nfrom sklearn.metrics import f1_score  # For model evaluation using F1-score\nfrom tqdm.notebook import tqdm        # For progress bars in notebook cells\nimport random                        # For reproducibility and randomization\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:35.168476Z","iopub.execute_input":"2025-05-24T09:55:35.168755Z","iopub.status.idle":"2025-05-24T09:55:35.174662Z","shell.execute_reply.started":"2025-05-24T09:55:35.168731Z","shell.execute_reply":"2025-05-24T09:55:35.173624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# Utility Function: Set Random Seed for Reproducibility\n# ============================================\n# Setting a random seed ensures that your results are reproducible.\n# This function sets the seed for Python's random module, NumPy, and PyTorch (both CPU and all GPUs).\n# Using the same seed each run will produce the same random numbers, which is important for debugging and sharing results[5][6].\n\ndef seed_everything(seed=42):\n    random.seed(seed)                  # Set seed for Python's built-in random module\n    np.random.seed(seed)               # Set seed for NumPy's random number generator\n    torch.manual_seed(seed)            # Set seed for PyTorch (CPU)\n    torch.cuda.manual_seed_all(seed)   # Set seed for all CUDA devices (GPUs), if available\n\n# Call the function at the start of your notebook or script to ensure reproducibility\nseed_everything()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:35.175710Z","iopub.execute_input":"2025-05-24T09:55:35.175985Z","iopub.status.idle":"2025-05-24T09:55:35.199717Z","shell.execute_reply.started":"2025-05-24T09:55:35.175965Z","shell.execute_reply":"2025-05-24T09:55:35.198703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input/soil-classification/soil_classification-2025'):\n    print(dirname)\n    for filename in filenames:\n        print(\"   \", filename)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:35.200783Z","iopub.execute_input":"2025-05-24T09:55:35.201084Z","iopub.status.idle":"2025-05-24T09:55:35.240125Z","shell.execute_reply.started":"2025-05-24T09:55:35.201060Z","shell.execute_reply":"2025-05-24T09:55:35.239108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_csv = '/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv'\ntest_csv = '/kaggle/input/soil-classification/soil_classification-2025/test_ids.csv'\ntrain_dir = '/kaggle/input/soil-classification/soil_classification-2025/train'\ntest_dir = '/kaggle/input/soil-classification/soil_classification-2025/test'\n\ntrain_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\nprint(train_df.head())\nprint(test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:40:03.943824Z","iopub.execute_input":"2025-05-24T10:40:03.944244Z","iopub.status.idle":"2025-05-24T10:40:03.965385Z","shell.execute_reply.started":"2025-05-24T10:40:03.944216Z","shell.execute_reply":"2025-05-24T10:40:03.964429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"soil_types = train_df['soil_type'].unique()\nlabel2idx = {label: idx for idx, label in enumerate(soil_types)}\nidx2label = {idx: label for label, idx in label2idx.items()}\n\ntrain_df['label'] = train_df['soil_type'].map(label2idx)\nprint(label2idx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:35.270316Z","iopub.execute_input":"2025-05-24T09:55:35.270629Z","iopub.status.idle":"2025-05-24T09:55:35.279551Z","shell.execute_reply.started":"2025-05-24T09:55:35.270608Z","shell.execute_reply":"2025-05-24T09:55:35.278589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df_, val_df = train_test_split(\n    train_df, test_size=0.15, stratify=train_df['label'], random_state=42)\nprint(f\"Train size: {len(train_df_)}, Validation size: {len(val_df)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:35.280596Z","iopub.execute_input":"2025-05-24T09:55:35.280863Z","iopub.status.idle":"2025-05-24T09:55:35.304423Z","shell.execute_reply.started":"2025-05-24T09:55:35.280843Z","shell.execute_reply":"2025-05-24T09:55:35.303468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision.transforms as transforms\n\nIMG_SIZE = 224 \n\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),             \n    transforms.RandomHorizontalFlip(),                       \n    transforms.RandomVerticalFlip(),                     \n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), \n    transforms.ToTensor(),                               \n    transforms.Normalize(mean=[0.485, 0.456, 0.406],      \n                         std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:35.305686Z","iopub.execute_input":"2025-05-24T09:55:35.306013Z","iopub.status.idle":"2025-05-24T09:55:35.321802Z","shell.execute_reply.started":"2025-05-24T09:55:35.305986Z","shell.execute_reply":"2025-05-24T09:55:35.320929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nimport os\n\nclass SoilDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, is_test=False):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx]['image_id']\n        img_path = os.path.join(self.img_dir, img_id)\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        if self.is_test:\n            return image, img_id\n        label = self.df.iloc[idx]['label']\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:35.323113Z","iopub.execute_input":"2025-05-24T09:55:35.323494Z","iopub.status.idle":"2025-05-24T09:55:35.347221Z","shell.execute_reply.started":"2025-05-24T09:55:35.323461Z","shell.execute_reply":"2025-05-24T09:55:35.346189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataset = SoilDataset(train_df_, train_dir, transform=train_transform)\nval_dataset = SoilDataset(val_df, train_dir, transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:35.348243Z","iopub.execute_input":"2025-05-24T09:55:35.348626Z","iopub.status.idle":"2025-05-24T09:55:35.371714Z","shell.execute_reply.started":"2025-05-24T09:55:35.348594Z","shell.execute_reply":"2025-05-24T09:55:35.370848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\n\nlocal_weights_path = '/kaggle/input/resnet/resnet18-f37072fd.pth' \n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\nmodel = models.resnet18(weights=None)\nstate_dict = torch.load(local_weights_path, map_location='cpu') \nmodel.load_state_dict(state_dict)\n\n\nmodel.fc = nn.Linear(model.fc.in_features, 4)\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:35.372715Z","iopub.execute_input":"2025-05-24T09:55:35.372961Z","iopub.status.idle":"2025-05-24T09:55:36.126123Z","shell.execute_reply.started":"2025-05-24T09:55:35.372944Z","shell.execute_reply":"2025-05-24T09:55:36.125218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:36.127038Z","iopub.execute_input":"2025-05-24T09:55:36.127327Z","iopub.status.idle":"2025-05-24T09:55:36.134283Z","shell.execute_reply.started":"2025-05-24T09:55:36.127296Z","shell.execute_reply":"2025-05-24T09:55:36.133490Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom tqdm import tqdm\n\ndef train_one_epoch(model, loader, optimizer, criterion):\n    model.train()\n    running_loss = 0.0\n    for images, labels in tqdm(loader):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n    return running_loss / len(loader.dataset)\n\ndef validate(model, loader):\n    model.eval()\n    preds, targets = [], []\n    with torch.no_grad():\n        for images, labels in loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            preds.extend(predicted.cpu().numpy())\n            targets.extend(labels.numpy())\n    f1s = f1_score(targets, preds, average=None, labels=[0,1,2,3])\n    min_f1 = f1s.min()\n    return min_f1, f1s\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:36.136011Z","iopub.execute_input":"2025-05-24T09:55:36.136352Z","iopub.status.idle":"2025-05-24T09:55:36.152180Z","shell.execute_reply.started":"2025-05-24T09:55:36.136322Z","shell.execute_reply":"2025-05-24T09:55:36.151218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 10\nbest_min_f1 = 0\n\nfor epoch in range(EPOCHS):\n    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n    min_f1, f1s = validate(model, val_loader)\n    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Min F1={min_f1:.4f}, F1s={f1s}\")\n    if min_f1 > best_min_f1:\n        best_min_f1 = min_f1\n        torch.save(model.state_dict(), 'best_model.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T09:55:36.154794Z","iopub.execute_input":"2025-05-24T09:55:36.155074Z","iopub.status.idle":"2025-05-24T10:19:21.288793Z","shell.execute_reply.started":"2025-05-24T09:55:36.155052Z","shell.execute_reply":"2025-05-24T10:19:21.287232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = SoilDataset(test_df, test_dir, transform=val_transform, is_test=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:29:29.145069Z","iopub.execute_input":"2025-05-24T10:29:29.145594Z","iopub.status.idle":"2025-05-24T10:29:29.154465Z","shell.execute_reply.started":"2025-05-24T10:29:29.145549Z","shell.execute_reply":"2025-05-24T10:29:29.153387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load('best_model.pth', map_location=device))\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:29:52.329432Z","iopub.execute_input":"2025-05-24T10:29:52.330360Z","iopub.status.idle":"2025-05-24T10:29:52.425879Z","shell.execute_reply.started":"2025-05-24T10:29:52.330328Z","shell.execute_reply":"2025-05-24T10:29:52.425003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_preds = []\nimage_ids = []\n\nwith torch.no_grad():\n    for images, img_ids in tqdm(test_loader):\n        images = images.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        all_preds.extend(predicted.cpu().numpy())\n        image_ids.extend(img_ids)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:30:16.092303Z","iopub.execute_input":"2025-05-24T10:30:16.092682Z","iopub.status.idle":"2025-05-24T10:30:31.989582Z","shell.execute_reply.started":"2025-05-24T10:30:16.092657Z","shell.execute_reply":"2025-05-24T10:30:31.988525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# idx2label was defined earlier\npred_labels = [idx2label[idx] for idx in all_preds]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:34:32.238486Z","iopub.execute_input":"2025-05-24T10:34:32.238955Z","iopub.status.idle":"2025-05-24T10:34:32.244484Z","shell.execute_reply.started":"2025-05-24T10:34:32.238928Z","shell.execute_reply":"2025-05-24T10:34:32.242987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\nsubmission = pd.DataFrame({\n    'image_id': image_ids,\n    'soil_type': pred_labels\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file saved as submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:53:58.972235Z","iopub.execute_input":"2025-05-24T10:53:58.972663Z","iopub.status.idle":"2025-05-24T10:53:58.982119Z","shell.execute_reply.started":"2025-05-24T10:53:58.972633Z","shell.execute_reply":"2025-05-24T10:53:58.981127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}